\chapter{Results}

Having designed and implemented the gaze tracker, we shall now evaluate its performance.
There are three aspects to consider when talking of performance: robustness, precision and speed.

\section{Face Tracking}
Let us introduce the transformations available in face tracking by an example of two still images:
\todo{intuitively compare the face tracking methods on a real image}

\todo{explain that a more thorough comparison is not possible because the planar transformation between two faces is not clearly defined.}

\section{Iris Tracking}

For a start, we compared the overall performance on all data available.

There are two combined trackers in addition to all the simple ones.

The one called \textit{h;l} is a Hough tracker and a Limbus gradient tracker running in series, in this order.

In the tracker called \textit{chr;l}, we replaced the simple Hough tracker with a parallel combination of Correlation, Hough, and Radial trackers.
Again, the result is refined by the Limbus gradient tracker afterwards.

\begin{table}[h]
\centering
\begin{tabular}{l@{\hspace{1.5cm}}D{.}{.}{3.2}}
\toprule
\textbf{Algorithm} & \mc{\textbf{Mean [px]} \todo{Q1, Q2, Q3}} \\
\midrule
h;l & 7.30 \\
hough & 8.26 \\
chr;l & 11.97 \\
radial & 12.11 \\
correlation & 16.48 \\
bitmap & 28.55 \\
limbus & 35.23 \\
\bottomrule
\end{tabular}
\caption{Algorithm mean error}\label{t:algo-mean}
\end{table}

Looking at the quartiles Q1 and Q2, it seems that there are many nice cases where the algorithms perform much better.
Indeed, the results of \textit{h;l} combined tracker look like this:\\
\todo{graph.}

We evaluated the algorithms separately on each of our data sets:\\
\todo{table.}

We also selected a subset of the test images with high contrast and limited occlusion:\\
\todo{table.}

Apparently, the simple tracker based on Circle Hough Transformation provides the best result.
Its performance can be improved at subpixel scale by adding an additional step of the Limbus gradient maximization.

It is quite disappointing that a voting scheme based on three of our trackers appears to perform worse than the best of them.

We should note that our Radial tracker is considerably slower than all the remaining ones.
On overly large-resolution images, its execution time can actually harm the overall framerate of gaze recognition.
\todo{edit this when the results are done.}

\subsection{Failure Factors}
\label{s:results-eyecovar}

Apparently, the results of eye tracking depend heavily on the qualitative aspects of each image.
For this reason, we annotated each of our testing samples in the following regards:
\begin{itemize}
\item Iris brightness
\item \todo{more}
\end{itemize}
The quantities are expressed in a subjective scale from $1$ (effect not visible) to $3$ (severe impact) or $4$ (image is almost unrecognizable).
Apart from this, each eye sample has already been labeled with the iris radius.

As expected, there is a strong correlation between many of these quantities:
\begin{table}[h]
\centering
\begin{tabular}{l@{\hspace{1.5cm}}D{.}{.}{3.2}D{.}{.}{3.2}D{.}{.}{3.2}D{.}{.}{3.2}}
\toprule
\textbf{Algorithm} & \mc{\textbf{Size}} & \mc{\textbf{Iris}} & \mc{\textbf{Contrast}} & \mc{\textbf{Glare}}\\
\midrule
h;l & 21.44 & 0.17 & -0.14 & -0.49\\
hough & 16.68 & -0.11 & -0.09 & -0.49\\
chr;l & 33.03 & 1.80 & 0.19 & 0.73\\
radial & 37.92 & 0.61 & 0.02 & 0.76\\
correlation & 34.09 & 3.30 & -0.06 & 1.29\\
bitmap & 72.23 & 0.74 & 0.54 & 1.43\\
limbus & 46.57 & 0.54 & 0.37 & 0.41\\
\bottomrule
\end{tabular}
\caption{Covariance of mean error wrt. image properties}\label{t:algo-covar}
\end{table}

For completeness, we repeated this test with each of our 
\todo{repeated for each of the three data sets, referenced to the attachment for their description}

\section{Gaze Estimation}
\todo{the overall success rate of the algorithm on the videos from Tobii}\\
\todo{compare two trackers $\times$ two face trackers}

The program does not perform all that well when compared to the state of the art, but it is certainly much more than a proof of concept.

The results on flawless video streams are already usable, and challenging situations could perhaps be solved with more coding manpower.
\todo{\dots}
