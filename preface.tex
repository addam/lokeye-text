\chapter{Introduction}

The main idea behind this program is to view human eye as a means of communication.
It is rather intuitive for us to recognize other people's gaze just by looking at their face thanks to high contrast coloring of the eye itself.
The corresponding brain circuitry develops early in infants (@cite) and is equivalent among individuals.
This seems to be an evidence of evolutionary purpose---the human eye is built in a way so as to display the gaze clearly.
Therefore it should also be possible for a computer to estimate gaze from the data us humans have available, that is, a color image.

Thanks to the fact that almost every laptop computer or cell phone is now equipped with a video camera, the hardware requirements of this software are easy to satisfy.
Future programs built on top of this library will also exhibit minimal hardware requirements that enable them to be used almost immediately upon download and completely for free.

Eye trackers can actually be used for communication, namely for human-computer interaction.
Wide variety of algorithms have been proposed (@cite) for on-screen keyboard and general desktop control.
The user's center of attention can also serve as a cue for adaptive rendering in video games because the rest of the screen need not be displayed in full detail.
Possible applications in gaze tracking in cell phones are a vast topic, such as locking the screen when not looked at or displaying a note when somebody looks over your shoulder.

Hereby we offer an open-source solution in the belief that it will help further development within this scientific field.
The task itself is by certainly new, and as will be detailed in the following section, there are many software libraries that solve it.
Unfortunately, it is rare that such a library would be released with open source code, and these few are usually incomplete or outdated.

\todo{contributions: homography, radial iris locator}

By the author's preference, the program tends to rely on complex, rigid models.
Such an approach is also beneficial because models with more free parameters would require too much training data.

\section{History}

Perhaps a more appropriate heading of this section would be \textit{Unrelated Work}.
Indeed, before we get to the overview of our software competitors, we should shortly review past research of gaze tracking in general.
Its history spans half a century before the computer era.

The interest in eye tracking originates in the field of psychology.
Gaze designates the focus of attention of the subject, which in turn can tell much about ongoing cognitive processes.
Furthermore, eye movement itself is the result of a rather complex neural system; nowadays, it is perhaps the best studied part of human cognition.

In order to record data with reasonable precision, sophisticated mechanical structures were often built around the subject's head.
Eye movement was then measured either directly from an object attached to the eye, or indirectly from small displacements in the eye region.
An especially precise technique was developed by Yarbus in 1954 and requires to stick a mirror to the surface of the eye using a small suction cup.\footnote{
The article is not cited here because it has been published only in Russian and does not seem generally available.
However, Yarbus provides details on the method in \cite{yarbus1967}.
}
Eye movement can then be recorded directly on a piece of photographic film via the reflection of a point light source shining at the eyes.

A method known as \textit{electrooculography} provides a less invasive alternative.
There is a constant voltage gradient across the eye from back to front, in magnitude of about 1 mV.
Rotation of this small dipole is measurable, so it is possible to almost directly measure the speed at which the eye moves.
The advantage gained is temporal resolution: this method allows to draw a graph of angle against time.
However, the actual direction is an integral of the measured value, and therefore tends to deteriorate and spatial resolution is generally poor.

Details on other purely analog methods such as this can be found in a 1967 book by Yarbus \cite{yarbus1967}.
The various methods suggested for eye tracking since the end of 19th century are a story of human curiosity and can be seen as a proof of the effort directed towards this area.

\section{Related Work}

Rapid development of computers and digital video cameras has removed most of the hardware constraints mentioned so far.
The demand for non-intrusive gaze tracking is high in many branches of science; for example, it is obvious that the results of a psychological experiment can greatly vary with emotional influence of the environment.
Letting the subject move their head without constraints, invariance against head pose becomes a serious challenge.
Head pose estimation and gaze tracking are typically handled as two separate tasks to be performed in series.
Few approaches are able to encompass both of these tasks within a single model.

Many substantially different approaches have been suggested for head pose estimation, and there seems to be no consensus so far.
The tracker by Kanade, Lucas and Tomasi(@cite) is based on matching a template image using gradient descent optimization and can be considered the cornerstone of object tracking.
The original paper describes tracking a rectangular grayscale template by horizontal and vertical shift.
We should note here that such a problem can also be solved on a global scale, i.e. using normalized cross-correlation and the Fast Fourier Transform for high performance.
However, there have been numerous generalizations of this concept to a broader class of motion models such as affine(@cite) or perspective(@cite) transformations where global optimization is not feasible.
Our program uses many of these generalizations extensively.

An especially sophisticated generalization is the Adaptive Appearance Models(@cite) (AAM).
In this method, a planar mesh is overlaid on the object, subdividing the template image into polygon-shaped cells.
Each of the cells is responsible of stretching its cut-out image part when its vertices are displaced.
All vertices of the mesh can be displaced separately, and they are essentially the model parameters to be optimized.
The degrees of freedom of this model can be customized to application needs, so that the method will handle either rigid or soft-body transformations gracefully.

Purely geometric image transformations have poor invariance to changes in lighting, so they are well combined with element-wise image transformations.
A simple option is to acquire multiple templates of the object in question, and either just select the best candidate for each input image, or allow their arbitrary linear combinations.(@cite)
If the amount of training data grows large, more efficient and robust schemes are necessary.
The template images can be arranged in a search structure \todo{\dots}

Each template need not be limited to a single image.
Instead, each of these images can be extended to a reasonable neighborhood by a per-pixel linear function.
The linear coefficients are typically estimated from several nearby templates using Principal Component Analysis, and this approach is widely known as Eigenfaces(@cite).
This approach leads to a mathematical concept of a high-dimensional manifold that covers all feasible face images.
By a further extension, each point in the high-dimensional space can be assigned six values that correspond to the six degrees of freedom of a rigid body.
In this view, a face tracker simply extracts these six parameters from the corresponding point in space.
Methods using this approach typically rely on high-level algebraic concepts to improve their performance.

Eye tracking is rather a simple task once the head pose is known.
However, there has not yet been a clear consensus on the appropriate method.
Much research relies on the fact that both human iris and pupil are circles, so their camera projection is always an ellipse.
When the gaze direction is reasonably bounded, these projected shapes can safely be considered to remain circular.
The generalized Hough transform(@cite) provides a global method of searching for circles with one-pixel precision.
In many applications(@cite), this is enough.

It is possible and sometimes more robust to use an appearance-based method, similar to the face tracking approaches outlined above.
\todo{\dots}

\todo{\dots}
Methods with partially controlled lighting are especially efficient for eye tracking because the mammalian eye is reflective both on its outer and the inner surface.
Human eyes are distincly reflective in red and near infrared light, which is the cause of the red-eye effect commonly observed in photography.
If an infrared light source is placed next to the camera, eyes in the image

\todo{finish}

\todo{youtubers}

\section{Notation}

We mostly follow the notation used in the classical book Multiple View Geometry \cite{b:hartley04}.
Boldface letters (e.g., $\vec x$) denote real column vectors.
Monospace letters (e.g., $\mat C$) denote real matrices.
An upper index next to these (e.g., $\mat C^i$) identifies the $i$-th matrix within a list, $n$-th power of matrix would be always expressed using parentheses, e.g., $(\mat S)^n$.
The central dot $\cdot$ can mean either scalar or matrix multiplication.

\todo{Something more..?}
