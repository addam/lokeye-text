\chapter{Introduction}

The main idea behind this program is to view human eye as a means of communication.
It is rather intuitive for us to recognize other people's gaze just by looking at their face thanks to high contrast coloring of the eye itself.
The relevant brain circuitry develops early in infants and is equivalent among individuals.
This seems to be an evidence of evolutionary purpose---the human eye is built in a way so as to display the gaze clearly \cite{tomasello07}.
Therefore it should also be possible for a computer to estimate gaze from the data us humans have available, that is, a color image.

Thanks to the fact that almost every laptop computer or cell phone is now equipped with a video camera, the hardware requirements of this software are easy to satisfy.
Future programs built on top of this library will also exhibit minimal hardware requirements that enable them to be used almost immediately upon download and completely for free.

The possible applications are a vast topic.
Along the communication concept, eye trackers can be used for human-computer interaction.
Wide variety of algorithms have been proposed for on-screen keyboard and general desktop control \cite{majaranta02}.
In contrast to classical input devices, they make computers accessible to disabled users that have difficulty to move their limbs.
They can also improve the user comfort, such as by speeding up mouse motion in accordance to the gaze.

Running a gaze tracker quietly in the background (perhaps in a low quality) can also be helpful.
When the screen of a cell phone is not looked at, it can automatically lock to improve security.
On the other hand, it can display a message when somebody reads over your shoulder.

The gaze provides valuable information even when we do not concentrate on it.
In psychological experiments, it is often used as a synonym of the subject's attention.
An industrial application of this method is found in marketing and user experience design, where gaze recordings can be used to evaluate the quality of presentation of a product, or of an interface layout.
Knowing the user's center of attention can also serve as a cue for adaptive rendering in video games because the rest of the screen need not be displayed in full detail.
Tracking the gaze of a car driver can be used to improve safety \cite{murphy-chutorian07}.

\section{History}

Perhaps a more appropriate heading of this section would be \textit{Unrelated work}.
Indeed, before we get to the overview of our software competitors, we should shortly review past research of gaze tracking in general.
Its history spans half a century before the computer era.

The interest in eye tracking originates in the field of psychology.
Gaze designates the focus of attention of the subject which in turn can tell much about ongoing cognitive processes.
Furthermore, eye movement itself is the result of a rather complex neural system; nowadays, it is perhaps the best studied part of human cognition.

In order to record data with a reasonable precision, sophisticated mechanical structures used to be constructed around the subject's head.
Eye movement was then measured either directly from an object attached to the eye, or indirectly from small displacements in the eye region.
For example, an especially precise technique was developed by Alfred Yarbus in 1954 and requires to stick a mirror to the surface of the eye using a small suction cup.\footnote{
The article is not cited here because it has been published only in Russian and does not seem generally available.
However, Yarbus provides details on the method in \cite{yarbus67}.
}
Eye movement can then be recorded directly on a piece of photographic film via the reflection of a point light source shining at the eyes.
We should note here that many other attachment mechanisms were less user-friendly than the suction cups.

A method known as \textit{electrooculography} provides a less invasive alternative.
Physiologically, there is a constant voltage gradient across the eye from back to front, in magnitude of about 1 mV.
Rotation of this small dipole generates a measurable magnetic field, so it is possible to almost directly measure the speed at which the eye moves.
The advantage gained is temporal resolution: this method allows to draw a graph of angle against time.
However, the actual direction is an integral of the measured value, and therefore tends to deteriorate and the spatial resolution is generally poor.

Details on other purely analog methods such as this can be found in a 1967 book \cite{yarbus67}.
The various methods suggested for eye tracking since the end of 19th century are a story of human curiosity and can be seen as a proof of the effort directed towards this area.

\section{Related work}

Rapid development of computers and digital video cameras has removed most of the hardware constraints mentioned so far.
The demand for non-intrusive gaze tracking is high in many branches of science; for example, it is obvious that the results of a psychological experiment can greatly vary with emotional influence of the environment.
Letting the subject move their head without constraints, invariance against head pose becomes a serious challenge.
Head pose estimation and gaze tracking are typically handled as two separate tasks to be performed in series.
Only few approaches are able to encompass both of these tasks within a single model.

\subsection{Face tracking}
\todo{explain what it is and why we need it}

Many substantially different approaches have been suggested for head pose estimation, and there seems to be no consensus so far.
The tracker by Kanade, Lucas and Tomasi \cite{lucas81} is based on matching a template image using gradient descent optimization and can be considered the cornerstone of object tracking.
The original paper describes tracking a rectangular grayscale template by horizontal and vertical shift.
Nowadays, such a simple problem can also be solved on a global scale, e.g., using normalized cross-correlation and the Fast Fourier Transform.
However, there have been numerous generalizations of this concept to a broader class of motion models such as affine (e.g., \cite{bouguet01}) or perspective transformations, in which cases a global optimization is not feasible.
These are often referred to as the \textit{deformable template models}.
Our program uses several of such generalizations extensively.

An especially sophisticated generalization are the Active Appearance Models (AAM) \cite{cootes01,stegmann00}.
In this method, a planar mesh is overlaid on the object, subdividing the template image into polygon-shaped cells.
Each of the cells is responsible of stretching its cut-out image part when its vertices are displaced.
All vertices of the mesh can be displaced separately, and they are essentially the model parameters to be optimized.
The degrees of freedom of this model can be customized to application needs, so that the method will handle either rigid or soft-body transformations gracefully.
The original paper suggests to learn the constraints by a Principal Component Analysis of manually 

Purely geometric image transformations exhibit poor invariance to changes in lighting, so they are well combined with element-wise image transformations.
A simple option is to acquire multiple templates of the object in question, and either just select the best candidate for each input image, or allow their arbitrary linear combinations.
If the amount of training data grows large, more efficient and robust schemes are necessary.
The template images can be arranged in a search structure to speed up the lookup of the most similar template (i.e., nearest neighbor).

A template need not be limited to a single image, and may be given implicitly as in \cite{gourier06}.
It is especially common to extend each template by a per-pixel linear function in a small neighborhood.
The linear coefficients are typically estimated from several nearby templates using Principal Component Analysis, and this approach is widely known as Eigenfaces \cite{srinivasan02,morency03}.
This approach leads to a mathematical concept of a high-dimensional manifold that covers all feasible face images.
Each point in the high-dimensional space can be assigned a feature vector that correspond to the modeled degrees of freedom \cite{balasubramanian07}.
In this view, a face tracker simply extracts these parameters from the corresponding point in space.


\todo{hlavac uricar \cite{uricar12} since they are in the thesis assignment}
\todo{wang shi 16 \cite{wang16} etc. thoroughly}

\todo{approaches using a depth map}

For a thorough comparison of all the face tracking methods in terms of performance and requirements upon the input data, we can recommend the excellent (althought slightly outdated) survey \cite{murphy-chutorian09}.

There have also been many software tools published aside from the scientific journals.
Some of them are available including the source code such as \cite{eviacam}.
Others are shared only as a video recorded from the system running\footnote{
As an example, several videos on the Youtube website:
\ahref{https://youtu.be/Etj\_aktbnwM},
\ahref{https://youtu.be/dZXz3egT7MI},
\ahref{https://youtu.be/1aNTsrEGM-8} also presented in \cite{valenti08},
\ahref{https://youtu.be/wlrR33JC3zw}.
}

\subsection{Eye tracking}
\label{s:related-gazetracking}
\todo{explain what it is and why we need it}

Eye tracking is rather a simple task once the head pose is known---it almost feels that the eyes are designed for easy tracking.
However, there has not been a clear consensus on the appropriate method, so far.
It appears that many of the methods that have been proposed in the literature are only appropriate in conditions specific to each of them.

Much research relies on the fact that both human iris and pupil are circles, so their camera projection is always an ellipse.
When the gaze direction is reasonably bounded, these projected shapes can safely be considered to remain circular.
For example, the generalized Hough Transform provides a global method of searching for circles with one-pixel precision.
Many alternative but quite similar models are tested in this thesis and available in the accompanying source code.
\todo{mean shift algorithm}

It is quite common to model some more specific aspects of the eye.
A reasonable choice are the eye corners \cite{zhu12} and the eyelids \cite{yuille92}.

It is possible and sometimes more robust to use an appearance-based method \cite{tan02}, that is, crop out a small image in the eye region and consider its all pixels a high-dimensional vector.
This approach usually requires the eye position to be precisely normalized to a center point, so that eye images with varying gaze directions only differ in the iris and pupil position.
Obviously, there are many free parameters (such as iris color, skin tone, shape of the eyelids and amount of eyelashes) that ought to be ignored by the gaze tracker.
To this end, it is necessary to provide enough training data that covers all these cases, to prevent overfitting.

Contrary to these methods based solely on an image, many rely on some extra hardware, such as cameras or lights.
Methods with partially controlled lighting are especially efficient for eye tracking because the mammalian eye is reflective both on its inner and its outer surfaces.
The retina of the human eye is distincly reflective in red and near infrared light, which is the cause of the red-eye effect commonly observed in photography.
If an infrared light source is placed next to the camera, the user's pupils will shine brightly, whereas the rest of the eye and the scene brightens only subtly.
The pupil shape can be obtained by contrasting this image to the one when the infrared light is turned off.

Having a point light source in a known position relatively to the camera also creates predictable reflections on the outer eye surface, called the \textit{Purkinje images} \cite{hansen10}.
The shape of the eye is just quite enough complex (as detailed in Section \ref{s.eyeanatomy}) and almost the same across individuals, so the eye pose can be deduced from such glares by geometric calculations.
As shown in \cite{villanueva08}, this approach can be used for precise tracking with only minimal calibration.

Devices using Purkinje reflections can be identified easily, since they contain several infrared lights that quickly switch on and off.
According to the author's experience, the Tobii EyeX tracker \cite{tobii} belongs to this group.
The tracker has been used to obtain some of our testing data; for a more detailed description, see Attachment \ref{s:testingdata}.
Tobii is one of the pioneer corporations in eye tracking, and many of their products are available on the market.

If even higher precision is required, it may still be necessary to attach a camera to the user's head and point it closely to the eyes.
Although such methods are slowly being deprecated by the less intrusive ones presented so far, it is important to note that there has also been much advancement in camera manufacturing.
Indeed, it is possible to build very small and lightweight cameras that will make almost no obtrusion to the user's view and comfort \cite{pupil,kassner14}.
Such a tracking rig may be preferred in many controlled scenarios such as in psychological laboratories.

For a thorough survey of eye trackers including the obscure historical ones, the reader is directed to \cite{hansen10}.

Regarding the relation between eye rotation and on-screen gaze position, some sources suggest that only a linear function is necessary \cite{zhu12}.
On the other hand, if the head and scene model is precise enough, it may be appropriate to calculate the gaze explicitly as a ray in space \cite{wang16}.

\todo{talk about available data sets}
\todo{what about dataset http://csr.bu.edu/headtracking/uniform-light/}

\section{Organization}
\todo{describe each chapter}

The directory structure of the accompanying data medium is explained in Attachment \ref{s:dirstructure}.

\section{Notation}

For matrix algebra we follow the notation used in the classical book Multiple View Geometry \cite{hartley03}.

\begin{table}[h!]
\centering
\begin{tabularx}{\textwidth}{lX}
$c$ & lowercase letter \dotfill real constant \\
$\diag$ & regular type word \dotfill function \\
$F$ & uppercase letter \dotfill a function or a set \\
$\vec x$ & boldface letter \dotfill real column vector \\
$\mat M$ & uppercase monospace letter \dotfill real matrix \\
$\mat M\inv$ & \dotfill inverse matrix \\
$\mat M^i$ & \dotfill indexed matrix name (e.g., index in a list of matrices) \\
$\cdot$ & central dot symbol \dotfill scalar or matrix multiplication \\
$|\vec x|$ & vertical bars \dotfill vector $L_2$ norm \\
\end{tabularx}
\end{table}
